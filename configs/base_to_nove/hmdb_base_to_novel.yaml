resume:   #'/media/sda1_acces/Code/ActionCLIP_without_wandb/Prompt_Adaptor_mix_work/Exp/clip_k400/ViT-B/16/kinetics400/base_to_novel_hmdb_test_attention//last_model.pt'
pretrain: #'/media/sda1_acces/Code/ActionCLIP_without_wandb/Prompt_Adaptor_mix_work/Exp/clip_k400/ViT-B/16/kinetics400/base_to_novel_hmdb_test_attention/last_model.pt'
weight_save_dir: 'Exp'
seed: 1024
training_name: 'base_to_novel_hmdb'
use_motion_loss: True
T_Adapter: False
prompt:
    use: True
    # num_of_token: 100 #197
    # num_of_text_token: 50   #77
    INITIATION: 'random' 
    DEEP: True
    DROPOUT: 0.1
data:
    dataset: HMDB51_base_to_novel
    modality: RGB
    num_segments: 8
    seg_length: 1
    batch_size: 20
    workers: 16
    # num_classes: 400
    image_tmpl: 'img_{:05d}.jpg'
    use_llm: True
    ###################################### K-400 ############################
    train_list: 'dataset_splits/HMDB/base_to_novel/hmdb_base_train.txt'
    val_list: 'dataset_splits/HMDB/base_to_novel/hmdb_base_val.txt' #
    gpt_discription: 'GPT_discription/HMDB_gpt_Class_discription_new.csv'
    label_list: 'dataset_splits/HMDB/base_to_novel/hmdb_base_train_class_list.csv'
    ###################################### Something-Something ############################
    ############## HMDB Val detail ################
    novel_val_list: 'dataset_splits/HMDB/base_to_novel/hmdb_novel_val.txt' #
    novel_gpt_discription: 'GPT_discription/HMDB_gpt_Class_discription_new.csv'
    novel_label_list: 'dataset_splits/HMDB/base_to_novel/hmdb_novel_val_class_list.csv'
    ############## K60 Val detail ################
    #############
    index_bias: 1
    input_size: 224
    randaug:
        N: 0 #2
        M: 0  #9
    random_shift: False #True
network:
    arch: ViT-B/16 #ViT-B/32 ViT-B/16 ViT-L/14
    init: True
    tsm: False
    drop_out: 0.1
    emb_dropout: 0.0 
    type: clip_hmdb
    sim_header: "Transf"  #Transf   meanP  LSTM Conv_1D Transf_cls
    joint: False
    describe:
    Return_Attention: False
solver:
    type: cosine
    epochs: 50
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 1.e-4    #5.e-6
    lr_warmup_step: 5
    momentum: 0.9
    weight_decay: 0.2
    lr_decay_step: 15
    lr_decay_factor: 0.1
    clip_gradient: 20
    loss_type: nll
    evaluate: False
    ratio: 1
    f_ratio: 10
logging:
    print_freq: 10
    eval_freq: 1